<!DOCTYPE html>
<html lang="en">
<head>
  <title>ReFACT</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="ReFACT: Updating Text-to-Image Models by Editing the Text Encoder. Dana Arad, Hadas Orgad, and Yonatan Belinkov.">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.4/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
<script src="https://kit.fontawesome.com/a20d977f12.js" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link href="https://fonts.googleapis.com/css?family=Google+Sans" rel="stylesheet">
  <style>

  mark {
  -webkit-animation: 1.5s highlight 1.5s 1 normal forwards;
          animation: 1.5s highlight 1.5s 1 normal forwards;
  background-color: none;
  background: linear-gradient(90deg, #bcf7cf 50%, rgba(255, 255, 255, 0) 50%);
  background-size: 200% 100%;
  background-position: 100% 0;
}

@-webkit-keyframes highlight {
  to {
    background-position: 0 0;
  }
}

@keyframes highlight {
  to {
    background-position: 0 0;
  }
}

  . {
  font-family: verdana;
  }
    /* Remove the navbar's default margin-bottom and rounded borders */
    .navbar {
      margin-bottom: 0;
      border-radius: 0;
    }

    /* Set height of the grid so .sidenav can be 100% (adjust as needed) */
    .row.content {height: 450px}

    /* Set gray background color and 100% height */
    .sidenav {
      padding-top: 20px;
      background-color: #f1f1f1;
      height: 100%;
    }

    /* Set black background color, white text and some padding */
    footer {
      background-color: #555;
      color: white;
      padding: 15px;
    }

    /* On small screens, set height to 'auto' for sidenav and grid */
    @media screen and (max-width: 767px) {
      .sidenav {
        height: auto;
        padding: 15px;
      }
      .row.content {height:auto;}
    }
  </style>
</head>
<body>


<div class="container-fluid text-center">
  <div class="row content">
    <div class="col-sm-2">
    </div>
    <div class="col-sm-8">
        <br>
        <div style="border-bottom: 2px solid black;" class="text-center">
        <div class="rounded  text-center">
      <h1 style="font-family: verdana;">ReFACT: Updating Text-to-Image Models by Editing the Text Encoder</h1>
                <center><table class="text-center" style="padding-top:16px;width:85%;margin-bottom:12px;margin-top:12px;font-size:16px;font-family: verdana;">
                <tr><td class="pad-cell"></td>
                <td class="author-cell"><a href="https://danaarad.github.io/">Dana Arad</a><sup>*</sup></td>
                <td class="author-cell"><a href="https://orgadhadas.github.io/">Hadas Orgad</a><sup>*</sup></td>
                <td class="author-cell"><a href="https://www.cs.technion.ac.il/~belinkov/">Yonatan Belinkov</a></td>
                <td class="pad-cell"></td></tr>
                <tr>
                <td class="eq-cell" colspan="2"><small><sup>*</sup>Equal contribution.</small></td>
                <td class="institution-cell"><br> Technion - Israel Institute of Technology</td>
                <td colspan="2"></td></tr>
                </table></center>
        </div>
        <div class="rounded" style="padding:5px">
                <a href="https://arxiv.org/abs/2306.00738" class="btn btn-success" style="background-color:#5bb072;"><i class="ai ai-arxiv"></i> ArXiv</a>
                <a href="./ReFACT Updating Text-to-Image Models by Editing the Text Encoder.pdf" type="button" class="btn btn-danger"  style="background-color:#e35a3b;"><i class="far fa-file-pdf"></i> PDF</a>
                <a href="https://github.com/technion-cs-nlp/ReFACT" type="button" class="btn btn-dark" style="background-color:#587a5ff;"><i class="fab fa-github"></i> Code</a>
                <!--<a href="" type="button" class="btn btn-warning btn-gradio" style="background-color:#ebb45b;">&#129303; Demo</a><br />-->
            </div><br>
        </div>
        <img src="./images/small_examples.png" class="center-block" alt="ReFACT Examples" width="100%">

        <br><br>
        <div>
        <h2 style="font-family: verdana;">Abstract</h2>
        <p style="font-size:16px;font-family: verdana;line-height: 1.6;">
            Text-to-image models are trained on extensive amounts of data, leading them to implicitly encode factual knowledge within their parameters.
            While some facts are useful, others may be incorrect or become outdated (e.g., the current President of the United States).
            <mark>We introduce ReFACT, a novel approach for editing factual knowledge in text-to-image generative models.
            ReFACT updates the weights of a specific layer in the text encoder, only modifying a tiny portion of the model’s parameters (0.24%), and leaving the rest of the model unaffected.</mark>
            We empirically evaluate ReFACT on an existing benchmark, alongside RoAD, a newly curated dataset.
            ReFACT achieves superior performance in terms of generalization to related concepts while preserving unrelated concepts.
            Furthermore, ReFACT maintains image generation quality, making it a valuable tool for updating and correcting factual information in text-to-image models.
        </p>
      <hr>
      <h3 style="font-family: verdana;">The Text Encoder in Text-to-Image Models</h3>
        <img src="./images/t2i_models.png" class="center-block" alt="Text-to-Image Models" width="100%">
      <p style="font-size:16px;font-family: verdana;line-height: 1.6;" class="text-left">
          Text-to-image diffusion models are pipelines composed of several individual modules.
          Common architectures consist of a text encoder - used to generate latent representations of an input prompt - an image generation module, and a cross-attention module that connects the two modalities.
          Several text-to-image diffusion models utilize CLIP in different capacities, specifically as a popular choice for a multi-modal-aware text encoder.

      </p>
              <hr>
      <h3 style="font-family: verdana;">Editing the Text Encoder</h3>
      <p style="font-size:16px;font-family: verdana;line-height: 1.6;">
          ReFACT takes an edit prompt (e.g., “The President of the United States”) and a target text (“Joe Biden”) or a target image (an image of Biden) that reflects the desired edit,
          and edits a specific layer in the model.
          The goal is to make the model’s representation of the prompt similar to that of the target text/image.
<br><br>
          ReFACT views facts as key–value pairs encoded in linear layers of the text encoder and updates the weights of a specific layer using a rank one editing approach.
          The edit consists of replacing the value (“Donald Trump → “Joe Biden”) for a corresponding key (“United States President”), and thus does not require fine-tuning the model.
<br>
      </p>
            <img src="./images/method.png" class="center-block" alt="Editing the text encoder using ReFACT" width="100%">
            <p style="font-size:16px;font-family: verdana;line-height: 1.6;"><br>
          We obtain the representation of the target by passing it through the respective frozen CLIP encoder and taking the output at the [EOS] token.
          Then, we compute a vector v<sup>*</sup> that, when inserted in a specific layer, will reduce the distance between the edit prompt representation and the target representation,
          resulting in the insertion of the edited fact into the model.</p>
            <br><br>
			 <img src="./images/more_examples.png" class="center-block" alt="Examples of edits using ReFaCT" width="100%">
			 <br><br>
			<hr>
      <h3 style="font-family: verdana;">Generalization and Specificity</h3>
      <p style="font-size:16px;font-family: verdana;line-height: 1.6;" class="text-left">
          ReFACT is able to generalize to closely related prompts. For instance, after editing “Canada’s Prime Minister” to be Beyonce,
          the model successfully generates images of Beyonce giving a speech in front of the Canadian flag for the prompt “Canada’s PM giving a speech”.
      </p>
            <img src="./images/generality.png" class="center-block" alt="ReFACT is able to generalize to closely related prompts" width="100%">
            <p style="font-size:16px;font-family: verdana;line-height: 1.6;" class="text-left">ReFACT also preserves unrelated concepts.
                For example, when editing "A lamp" to "A lava lamp", the model is still able to generate an image of a lightbulb.</p>
            <img src="./images/specificity.png" class="center-block" alt="ReFACT is does not affect unrelated prompts" width="100%">
			
		<hr>
		<h3 style="font-family: verdana;">Citation</h3>
		<pre style="text-align: left; background-color:#E1E1E1;"><code>
  @article{arad2023refact,
	  title={Refact: Updating text-to-image models by editing the text encoder},
	  author={Arad, Dana and Orgad, Hadas and Belinkov, Yonatan},
	  journal={arXiv preprint arXiv:2306.00738},
	  year={2023}
	}
</code></pre>
		
        </div>

    </div>
    <div class="col-sm-2"></div>
  </div>
</div>

</body>
</html>
